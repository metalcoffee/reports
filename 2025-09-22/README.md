# Рецензия

---

## Оригинальность

### Предлагает ли работа новые идеи, углубляет ли понимание или выявляет важные свойства существующих подходов?


#### Новая постановка проблемы
Workload — интерактивные микросервисы с временем выполнения rpc в сотни микросекунд. Убеждающе говорят, что существующие FaaS-системы (на примере AWS Lambda, OpenFaaS)
с их миллисекундными накладными расходами на вызов совершенно не подходят для этой цели, что ставит в целом новое важное направление для развития serverless
#### Новая цель проектирования
Авторы формулируют две конкретные цели производительности для FaaS-рантайма в этом контексте: накладные расходы на вызов <100 мкс и пропускная способность ≥100K вызовов/с.

#### Новое архитектурное решение — fast path для внутренних вызовов
Ключевая идея - разделение вызовов функций на внешние (generated by a client, received by the gateway),  и внутренние (generated by the execution of a microservice).
Авторы замечают, что в микросервисных приложениях внутренние вызовы доминируют и предлагают оптимизировать их, выполняя на том же рабочем сервере, полностью минуя gateway.
Это фундаментальное отличие архитектуры Nightcore от классических FaaS-систем (OpenWhisk, OpenFaaS) и важное понимания того, как следует проектировать FaaS для взаимосвязанных workloadов, а не просто для изолированных функций.

#### Углубление понимания управления параллелизмом
авторы упоминают, что есть важное свойство микросервисных нагрузок — изменчивость нагрузки даже при стабильном внешнем потоке запросов — и то, как слепое увеличение параллелизма (максимизация числа worker тредов) 
может привести к коллапсу производительности из-за каскадного эффекта.
В ответ этой проблеме авторы предлагают адаптивную систему управления параллелизмом на основе динамически вычисляемых подсказок (concurrency hints τ_k),
это является хорошим вкладом в понимание того, как управлять ресурсами в высокодинамичной среде

### Понятно ли, чем эта работа отличается от предыдущих работ, достаточно ли ссылок на смежные работы?

#### Четкое отличие
Заметное противопоставление своего подхода другим известным системам:
- против подхода OpenFaaS/OpenWhisk: их архитектура с обязательным прохождением через gateway создает неприемлемые задержки из-за сетевого RTT
- против SAND: отмечается, что SAND оптимизирует только одиночные последовательные вызовы (один локальный вызов в конце), тогда как Nightcore поддерживает произвольные графы вызовов
- против Faasm: подчеркивается, что Faasm полагается на программную изоляцию (WebAssembly), что слабее контейнерной изоляции, которую предоставляет и требует Nightcore
- против решений, ослабляющих изоляцию: утверждается, что предпочтение отдается сильной контейнерной изоляции, а не более быстрой, но слабой SFI (Software-based Fault Isolation)

#### Достаточность ссылок: 
Список литературы мягко скажем достаточен и больше (113 источников), охватывает все ключевые смежные темы:

- микросервисы и их характеристики ([70], [100], [101])
- существующие FaaS-платформы и их производительность ([37], [50], [55])
- предшественники в области низколатентных FaaS ([62], [98])
- исследования в области оптимизации ОС для микросекундных задач (название просто огонь: Attack of the Killer Microseconds [60], планировщики [92], dataplane OS [91])
- управление перегрузкой и параллелизмом в микросервисах ([38], [73], [105])

### Являются ли задачи/методы из статьи новыми или же новой комбинацией известных (это тоже может быть ценно)?

Имхо тяжело себе представить что-то настолько новое, что вот прям можно сказать, что никакая его часть не похожа на что-то уже известное.
Но все же эта статья скорее представляет собой новый подход с уже известнми методами: использование событийно-ориентированной модели (libuv) для эффективного I/O, разделяемая память + pipes для низколатентного IPC, адаптивное управление параллелизмом на основе закона Литтла — все эти методы сами по себе не являются новыми

Новая комбинация и адаптация, как раз в этом ценность статьи, как эти методы собраны вместе и как они оптимизированы для микросекундного масштаба в контексте FaaS:

- сочетание контейнерной изоляции с таким низким уровнем накладных расходов
- архитектурное решение с быстрым путем для внутренних вызовов — это новая комбинация идеи локализации вычислений и FaaS-исполнения
- адаптация управления параллелизмом, работающая на уровне отдельных функций и обновляющаяся в микросекундном масштабе — это существенное развитие известного принципа.

## Качество

### Является ли работа технически обоснованной?
Да ну конечно да. Проблема которую решают: миллисекундные задержки вызова в традиционных FaaS неприемлемы для микросекундных микросервисов с помощью того что каждый компонент 
Nightcore (обход gateway для внутренних вызовов, низколатентные каналы, управление параллелизмом) направлен на устранение конкретного источника задержки, выявленного в ходе анализа

### Хорошо ли подкреплены утверждения авторов (например, теоретическим анализом или экспериментальными результатами)?
- количественная оценка проблемы: в таблице 1 приведены конкретные цифры задержек вызова для AWS Lambda, OpenFaaS и Nightcore, сразу показывая масштаб проблемы и преимущество решения
- сравнение: основные эксперименты (рисунок 7) проводятся против двух бейзлайнов: классических RPC-серверов в контейнерах (золотой стандарт производительности) и OpenFaaS (представитель классического FaaS)
- анализ масштабируемости: в таблице 4 показано, как система ведет себя на кластере из нескольких серверов, доказывая, что предложенная архитектура работает не только на одной машинке
- декомпозиция вклада компонентов: рисунок 8 является ключевым доказательством обоснованности дизайна, авторы последовательно добавляют компоненты системы и показывают вклад каждого из них в общий прирост производительности
- анализ производительности: таблица 6 с breakdown потребления CPU через сэмплирование стека, наглядно показывает, куда уходит время в RPC-серверах (сетевое ядро ОС) и в Nightcore (пользовательское пространство)

### Адекватны ли используемые методы?
Ага, более чем: DeathStarBench, HipsterShop вместо синтетических нагрузок, стандартный нагрузочный инструмент (wrk2) и облачные платформы (AWS EC2), сравнение с RPC-серверами и OpenFaaS
,измерение не только средней задержки, но и 99-го перцентиля, измерение пропускной способности и утилизации CPU

### Это законченная работа или промежуточный результат?
Поддержка нескольких языков программирования (C/C++, Go, Node.js, Python), код системы открыт и выложен на GitHub
### Корректны и честны ли авторы в оценке сильных и слабых сторон работы?

Сильные стороны: подробно и с доказательствами изложены в результатах (высокая производительность, низкие задержки, эффективное управление параллелизмом).

Слабые стороны и ограничения (обсуждаются в Разделах 5.4 и 6): холодный старт, зависимость от Linux, изоляция,

## Ясность
### Насколько ясно написана статья, хорошо ли она структурирована? (Если нет, предложите, как можно это исправить.)
Более чем, структура соответсвует логичному развитию событий: интро, где ставится задача и обьясняется контекст, бэкграунд, где обьясняется все необходимое для дальнешего понимания,
потом идет собственно описание реализации и идеи, ну и под конец исследования, сравнения, итоги

### Содержит ли статья достаточно информации, чтобы опытный читатель мог воспроизвести ее результаты?

Как будто очень даже, достаточно открыть часть 5.1, где собственно описаны все методы, которые были применены + Artifact Appendix -- выше крыши, чтобы  подробно понять + репа

## Значимость
### Важны ли полученные результаты, насколько сильное влияние они могут оказать?
Работа решает противоречие между двумя трендами cloud computing: желанием использовать serverless-модель для снижения операционной сложности и жесткими требованиями к задержкам современных микросервисов.
Это не теоретическая проблема ведь с ним сейчас повсеместно сталкиваются разработчики в компаниях, подобных тем, что указаны во введении (Amazon, Netflix, Uber и т.д.)
### Вероятно ли, что другие исследователи и практики будут использовать эти идеи или развивать их?
Использований тоже выше крыши: архитектура с быстрым путем для внутренних вызовов (адаптация для других FaaS-системы и service mesh), управление параллелизмом на основе τ_k (могут перенять другие системы, сталкивающиеся с проблемами "каскадных перегрузок")

Развитие идей: собственно оптимизация всех недостатков: холодного старта,
поддержка stateful workload и тд

### Решает ли эта работа задачу лучшим образом, чем предыдущие работы?

Ага, да, см. [часть](#Четкое-отличие)

### Продвигает ли она уровень развития данной области?

Ага, это несомненно сдвиг типичной парадигмы мышления в этой области и новый потолок










