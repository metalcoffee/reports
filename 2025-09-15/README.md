# Мини-задание

Вы - автор, вам надо за несколько минут (в формате типа lightning talk)
рассказать про статью незнакомым с нею коллегам, так чтобы они заинтересовались и
прочитали ее. Напишите текст вашего выступления.

---
Основная проблема: слишком много памяти в дата-центрах простаивает просто потому что она привязана к конкретным серверам

Сейчас проблемрой частой является то, что многие загибаются от нехватки RAM, а соседние гб памяти просто простаивают.
Решение как раз этой проблемы предоставляют авторы — disaggregated memory. Cуть в том, что память *физически* отделена от процессоров и доступна по сети как отдельный пул ресурсов.

Есть некоторые но, например, как дать приложениям доступ к этой памяти чтобы это было достаточно быстро и чтобы например не нужно было переписывать код

Современные решения для этого используют виртуальную память.
Приложение обращается к данным, page fault, понимание, что данные лежат на удаленной машине, система прогружает целую страницу, кэширует ее локально и тд.

Логичный выход, но есть недостатки, например высокие задержки (каждый page fault это остановка приложения), dirty data (при изменении хотя бы 1 байта в этой странице на удаленный 
сервер для синхронизации всё равно придется отправить все страницу)

Поэтому суть подхода авторов статьи в том, чтобы использовать coherency кэшей

Cуть подхода в том чтобы использовать не page faults, а систему кэшей процессора для отслеживания обращений к памяти на уровне cache-lines.

Таким образовм больше нет page faults на critical path:
если данных нет в локальном кэше, процессор сам инициирует их запрос по сети, и что самое главное -- приложение не останавливается!

Еще есть точное отслеживание изменений: на удаленный сервер отправляются только те байты, которые были реально изменены, а не целая страница

В общем и целом есть несколько ключевых моментов в их статье

1) Вместо того чтобы просто эмулировать локальную память поверх сетевой, предлагаются удаленные регионы памяти: память выделяется большими блоками,
что уменьшает сетевые накладные расходы на частые операции выделения/освобождения

2) Оптимизация доступа через RDMA. Группировка нескольких операций чтения/записи в один сетевой пакет.
RDMA -- технология, которая позволяет одному компьютеру напрямую читать или писать в память другого компьютера без вовлечения его CPU, что снижает задержки и нагрузку на процессор.

3)  Перепроектирование менеджера памяти. Традиционные аллокаторы (например, malloc) неэффективны для удаленной памяти из-за сетевых задержек.
поэтому  предлагаются распределенные аллокаторы, которые учитывают задержку до разных пулов памяти и стараются выделять память "ближе"
 к вычислительному узлу. Чтобы избежать частых сетевых запросов, память выделяется большими порциями заранее.


Допустим, приложению на вычислительном узле нужна память:

- рантайм запрашивает большой блок памяти из пула дисэгрегированной памяти (через RDMA)
- внутри этого блока рантайм самостоятельно управляет выделением (аллокацией) для конкретных потребностей приложения, минимизируя сетевые взаимодействия
- при обращении к данным рантайм прозрачно для приложения обращается к удаленной памяти, используя кэширование и предвыборку для скрытия задержек


И благодаря этому авторы получили результаты:

- ускорение среднего времени доступа к памяти в 1.7-5 раз
- сокращение объема передаваемых «грязных» данных в 2-10 раз!
